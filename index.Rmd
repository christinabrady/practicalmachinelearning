---
title: 'Practical Machine Learning: Motion Analysis'
author: "Christina Brady"
date: "December 27, 2015"
output: html_document
---
```{r, echo = FALSE, cache = TRUE}
library(caret)
library(doMC)
registerDoMC(cores = 4)
set.seed(1979)
options(warn = -1)
source("../project/report_code.R")
```
# 1. Executive Summary

The objective of this analysis is to use data collected from human recognition activity monitors on the waist, wrist and bicep of 6 participantsplus one sensor on the dumbbell as they performed dumbbell curls in five different manners to classify in which manner the dumbbell curl is performed. They each performed the dumbbell curl "correctly" (as recommended) and they each performed the dumbbell curls making 4 common mistakes. The data is licensed under the Creative Commons license (CC BY-SA) and can be found here [link](http://groupware.les.inf.puc-rio.br/har). The nature of the problem being one of classification with relatively sparse data (the participants only performed 10 repetitions in five different manners), I chose to use a random forest both to aid in feature selection and as the predictive model. 

# 2. Data
I downloaded the data from the class website in csv format and read it into R. The initial dataset contains 19622 observations on 159 variables. The first six variables include the name of the participant, various time stamps and window classifications used by the authors of the study. Many of the other variables are composite or calculated variables such as minimun, maximum, mean or totals. Of the variables that are some form of data from the sensors, some variables imported as character, others imported as numeric and finally others imported as integer variables. By converting them all to numeric variables, I was able to determine that many of the variables have very sparse data.

# 3. Feature Selection
As mentioned above, there are three types of time stamp variables. A frequency table of user name, cvtd timestamp and classe shows that each person started with class A and then moved on to other classes. 

```{r}
table(pml$cvtd_timestamp, pml$classe, pml$user_name)[1:10, , 1]
```

Thus, the user names and time stamp will correlate highly with the class of the activity and would lead to over fitting, and should not be included in the analysis.

Next, using the following code, I determined which columns contain a significant number of missing values and eliminated those variable from the analysis. 
```{r}
natest <- function(c){
  return(as.character(summary(c)[7]))
}

createNAcolmap <- function(dat){
  for(i in 6:(ncol(dat)-1)){
    dat[, i] <- as.numeric(dat[, i])
  }
  nacol <- list()
  for(i in 1:ncol(dat)){
    nacol[[i]] <- natest(dat[, i])
  }
  map <- unlist(nacol)
  names(map) <- colnames(dat)
  return(map[!is.na(map)])  
}
nacolmap <- createNAcolmap(training)
elim_name <- c("raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window", "raw_timestamp_part_1", "user_name") ### eliminate after 


clean <- function(dat){
  dat$classe <- factor(dat$classe)
  nonas <- dat[,!(colnames(dat) %in% names(nacolmap))]
  return(nonas[, !(colnames(nonas) %in% elim_name)])
}

cleantraining <- clean(training)
```

That left 53 variables, so I trimmed those variables using the variable importance option in the random forest model. 
```{r}
rf7varImport <- train(classe~., method = "rf", data = cleantraining2, ntree = 100, importance = TRUE)
plot(rf7varImport)
```
This suggests that a model with 28 variables produces the best result. So, I took the mean importance across all 5 classes, ordered the variables according to the mean importance and extracted the top 28 variables. That left me with the following variables:
```{r}
varnames
```

# 4. Building the Model
I used the caret packages to split the data and train the model. Since the course provides a test set, I split the data as if I had a training set (80%), a cross validation set (20%) and a test set (unknown). I trained the model on the subset of the training data containing only the 28 variables mentioned above, and I tested my model on a subset of the test set also containing only the 28 variables mentioned above. 

# 5. Results
The accuracy of this model on this test set is 0.9962. 
```{r}
pred1 <- predict(lastrf, newdata = testsub)
confusionMatrix(pred1, testsub$classe)
```

Using the miss classification error, the out of sample error rate is:
```{r}
missClass <- sum(pred1 != testsub$classe)/length(pred1)
missClass
```


# References:
1. Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.


